{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29a4b823-ef5b-4ec0-8e01-a744a1395c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6ff8d81-3717-48b5-8428-b88fa41cb767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from transformers import GPT2Tokenizer, GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d22274f-f895-456b-abc2-631f0c011075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000\n"
     ]
    }
   ],
   "source": [
    "def process_file_fixed(file_path, num_rows=21000):\n",
    "    news = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            if i >= num_rows:\n",
    "                break\n",
    "            json_object = json.loads(line)\n",
    "            news.append(json_object)\n",
    "    return news\n",
    "\n",
    "file_path = r'C:\\Users\\dell\\Desktop\\MyDocs\\Docs\\MK\\News_Category_Dataset_v3.json'\n",
    "news = process_file_fixed(file_path, num_rows=21000)\n",
    "print(len(news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66932977-f6a4-4c96-9673-1cc89afb040f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'link': 'https://www.huffpost.com/entry/belk-worker-found-dead-columbiana-centre-bathroom_n_632c5f8ce4b0572027b0251d',\n",
       " 'headline': 'Cleaner Was Dead In Belk Bathroom For 4 Days Before Body Found: Police',\n",
       " 'category': 'U.S. NEWS',\n",
       " 'short_description': 'The 63-year-old woman was seen working at the South Carolina store on Thursday. She was found dead Monday after her family reported her missing, authorities said.',\n",
       " 'authors': '',\n",
       " 'date': '2022-09-22'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "817a66ee-355c-4e5c-b478-5275e37f006e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Cleaner Was Dead In Belk Bathroom For 4 Days Before Body Found: Police || The 63-year-old woman was seen working at the South Carolina store on Thursday. She was found dead Monday after her family reported her missing, authorities said.',\n",
       " 'U.S. NEWS')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cat_pairs = []\n",
    "\n",
    "for news_item in news:\n",
    "    headline = news_item.get(\"headline\")\n",
    "    short_description = news_item.get(\"short_description\")\n",
    "    text = headline + \" || \" + short_description\n",
    "    category = news_item.get(\"category\")\n",
    "    text_cat_pairs.append((text, category))\n",
    "\n",
    "text_cat_pairs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a1b50bb-1f61-4a68-9fbc-9f1a42c9b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries to encode and decode category labels\n",
    "label_to_index = {}  # Map category to index\n",
    "index_to_label = {}  # Map index to category\n",
    "i = 0  # Start index at 0\n",
    "\n",
    "# Populate the dictionaries with unique categories\n",
    "for (_, label) in text_cat_pairs:\n",
    "    if label not in label_to_index:  # If the label is not yet added\n",
    "        label_to_index[label] = i  # Assign it the next index\n",
    "        index_to_label[i] = label  # Map the index back to the label\n",
    "        i += 1  # Increment the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6192fdac-49c4-4106-b213-9ef37479b64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'U.S. NEWS': 0,\n",
       " 'COMEDY': 1,\n",
       " 'PARENTING': 2,\n",
       " 'WORLD NEWS': 3,\n",
       " 'CULTURE & ARTS': 4,\n",
       " 'TECH': 5,\n",
       " 'SPORTS': 6,\n",
       " 'ENTERTAINMENT': 7,\n",
       " 'POLITICS': 8,\n",
       " 'WEIRD NEWS': 9,\n",
       " 'ENVIRONMENT': 10,\n",
       " 'EDUCATION': 11,\n",
       " 'CRIME': 12,\n",
       " 'SCIENCE': 13,\n",
       " 'WELLNESS': 14,\n",
       " 'BUSINESS': 15,\n",
       " 'STYLE & BEAUTY': 16,\n",
       " 'FOOD & DRINK': 17,\n",
       " 'MEDIA': 18,\n",
       " 'QUEER VOICES': 19,\n",
       " 'HOME & LIVING': 20,\n",
       " 'WOMEN': 21,\n",
       " 'BLACK VOICES': 22,\n",
       " 'TRAVEL': 23,\n",
       " 'MONEY': 24,\n",
       " 'RELIGION': 25,\n",
       " 'LATINO VOICES': 26,\n",
       " 'IMPACT': 27,\n",
       " 'WEDDINGS': 28,\n",
       " 'COLLEGE': 29,\n",
       " 'PARENTS': 30,\n",
       " 'ARTS & CULTURE': 31,\n",
       " 'STYLE': 32,\n",
       " 'GREEN': 33,\n",
       " 'TASTE': 34,\n",
       " 'HEALTHY LIVING': 35}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d5d5ba8-315e-4718-8013-4a4afac1dd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'U.S. NEWS',\n",
       " 1: 'COMEDY',\n",
       " 2: 'PARENTING',\n",
       " 3: 'WORLD NEWS',\n",
       " 4: 'CULTURE & ARTS',\n",
       " 5: 'TECH',\n",
       " 6: 'SPORTS',\n",
       " 7: 'ENTERTAINMENT',\n",
       " 8: 'POLITICS',\n",
       " 9: 'WEIRD NEWS',\n",
       " 10: 'ENVIRONMENT',\n",
       " 11: 'EDUCATION',\n",
       " 12: 'CRIME',\n",
       " 13: 'SCIENCE',\n",
       " 14: 'WELLNESS',\n",
       " 15: 'BUSINESS',\n",
       " 16: 'STYLE & BEAUTY',\n",
       " 17: 'FOOD & DRINK',\n",
       " 18: 'MEDIA',\n",
       " 19: 'QUEER VOICES',\n",
       " 20: 'HOME & LIVING',\n",
       " 21: 'WOMEN',\n",
       " 22: 'BLACK VOICES',\n",
       " 23: 'TRAVEL',\n",
       " 24: 'MONEY',\n",
       " 25: 'RELIGION',\n",
       " 26: 'LATINO VOICES',\n",
       " 27: 'IMPACT',\n",
       " 28: 'WEDDINGS',\n",
       " 29: 'COLLEGE',\n",
       " 30: 'PARENTS',\n",
       " 31: 'ARTS & CULTURE',\n",
       " 32: 'STYLE',\n",
       " 33: 'GREEN',\n",
       " 34: 'TASTE',\n",
       " 35: 'HEALTHY LIVING'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5279d33c-7411-4221-b05b-911fb1627dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a label to its corresponding tensor representation\n",
    "def convert_labels(label):\n",
    "    return torch.tensor(label_to_index[label])  # Convert label to its encoded index\n",
    "\n",
    "# Convert all labels into tensors\n",
    "labels = [cat for (text, cat) in text_cat_pairs]  # Extract categories\n",
    "labels = [convert_labels(label) for label in labels]  # Convert each label to a tensor\n",
    "stacked_tensors_y = torch.stack(labels).long()  # Combine all label tensors into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "211a8920-4314-4cbc-8732-d7fb63596b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21000])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_tensors_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd7061e5-941b-4131-b380-e1ba386cbba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "embedding_model = GPT2Model.from_pretrained('gpt2').to('cpu')\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set padding token to <|endoftext|>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b42d4ca2-e3f9-44b9-8c58-96f54108eb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Woman Who Called Cops On Black Bird-Watcher Loses Lawsuit Against Ex-Employer || Amy Cooper accused investment firm Franklin Templeton of unfairly firing her and branding her a racist after video of the Central Park encounter went viral.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = text_cat_pairs[4][0]\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "deee4779-f452-42e0-bb57-6e7d40e073be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Woman', ' Who', ' Called', ' C', 'ops', ' On', ' Black', ' Bird', '-', 'W', 'atcher', ' L', 'oses', ' Law', 'suit', ' Against', ' Ex', '-', 'Employ', 'er', ' ||', ' Amy', ' Cooper', ' accused', ' investment', ' firm', ' Franklin', ' Temple', 'ton', ' of', ' unfairly', ' firing', ' her', ' and', ' branding', ' her', ' a', ' racist', ' after', ' video', ' of', ' the', ' Central', ' Park', ' encounter', ' went', ' viral', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.encode(ex)\n",
    "print([tokenizer.decode([t]) for t in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2c3e420-cdbf-466b-bce6-f2d168af805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to embed a single sentence using GPT-2\n",
    "def embed_sentence(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to('cuda')  # Tokenize and encode\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        outputs = embedding_model(**inputs)  # Forward pass through GPT-2\n",
    "    hidden_states = outputs.last_hidden_state  # Extract hidden states\n",
    "    sentence_embedding = hidden_states.mean(dim=1)  # Compute sentence embedding via mean pooling\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4275731-e77a-4708-93b9-9074340c3e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53716500-54cc-4cb1-8d1d-7d5b8720a6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embed_sentence(text):\n",
    "    # Tokenize and encode the text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to('cpu')  # Use CPU instead of GPU\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        outputs = embedding_model(**inputs)  # Forward pass through GPT-2\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)  # Get the sentence embedding (mean of token embeddings)\n",
    "    return embeddings\n",
    "\n",
    "embedded_example = embed_sentence(ex)\n",
    "embedded_example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dbaaf8-8c1c-4fc4-b760-488e4a301eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_sentences = [embed_sentence(text) for (text, cat) in text_cat_pairs]\n",
    "print(embedded_sentences[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b254d84e-6c5d-4881-8115-4eb84dc8dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embedded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42245f62-100e-4076-906a-a51d576c8263",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([x.shape[0] for x in embedded_sentences])\n",
    "\n",
    "# Pad the shorter sentences with zeros\n",
    "padded_sentences = []\n",
    "for sentence in embedded_sentences:\n",
    "  padding_length = max_len - sentence.shape[0]\n",
    "  if padding_length == 0:\n",
    "    padded_sentences.append(sentence)\n",
    "  else:\n",
    "    padding = torch.zeros(padding_length, sentence.shape[1])\n",
    "    padded_sentence = torch.cat((sentence, padding), dim=0)\n",
    "    padded_sentences.append(padded_sentence)\n",
    "\n",
    "# Stack the padded tensors\n",
    "stacked_tensors_x = torch.stack(padded_sentences)\n",
    "stacked_tensors_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b96e7b-fad5-405f-b28b-61df8d6ed0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    stacked_tensors_x, stacked_tensors_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dd1608-f827-4754-bcf9-514fc6b5e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    val_texts, val_labels, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc536a1f-85cb-4bf5-b99f-7db38dff69f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)  # 2 for bidirection\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get the device of the input tensor\n",
    "        device = x.device\n",
    "\n",
    "        # Set initial hidden and cell states on the same device as x\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)  # 2 for bidirection\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        last_hidden = self.fc(out[:, -1, :])  # Last time step\n",
    "        first_hidden = self.fc(out[:, 0, :])  # First time step\n",
    "        output = last_hidden + first_hidden\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac59f75-3577-4ff6-8214-8b87d3d6482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimensionality = stacked_tensors_x.shape[-1]\n",
    "num_classes = len(label_to_index)\n",
    "embedding_dimensionality, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc220e2-69b4-4e9f-b280-82e931004703",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimensionality = stacked_tensors_x.shape[-1]\n",
    "num_classes = len(label_to_index)\n",
    "input_size = embedding_dimensionality\n",
    "hidden_size = embedding_dimensionality\n",
    "num_layers = 2\n",
    "model = LSTM(input_size, hidden_size, num_layers, num_classes).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3763eb4-7ef1-4afb-af79-9baf712cf203",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(stacked_tensors_x.to('cpu'))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9ecfde-a304-490c-a3fe-ba32994610a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049dc554-8fa2-478c-ad98-457571caeaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_texts, train_labels, val_texts, val_labels, epochs, optimizer, criterion):\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(train_texts.to('cuda'))\n",
    "        loss = criterion(outputs, train_labels.to('cuda'))\n",
    "        train_loss_history.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_acc = (preds == train_labels.to('cuda')).float().mean().item()\n",
    "        train_acc_history.append(train_acc)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(val_texts.to('cuda'))\n",
    "            val_loss = criterion(val_outputs, val_labels.to('cuda'))\n",
    "            val_loss_history.append(val_loss.item())\n",
    "\n",
    "            _, val_preds = torch.max(val_outputs, 1)\n",
    "            val_acc = (val_preds == val_labels.to('cuda')).float().mean().item()\n",
    "            val_acc_history.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "              f\"Train Loss: {loss.item():.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "              f\"Val Loss: {val_loss.item():.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    return train_loss_history, val_loss_history, train_acc_history, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c873118-8764-4a62-b7bf-cf12b89d9917",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "train_loss, val_loss, train_acc, val_acc = train_model(\n",
    "    model, train_texts, train_labels, val_texts, val_labels, epochs, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eab0ddf-c08d-4da5-9825-3e4032647b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(train_history, val_history, metric_name):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train_history, label=f'Train {metric_name}')\n",
    "    plt.plot(val_history, label=f'Validation {metric_name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.title(f'{metric_name} over Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131020d-73e5-4f5a-b49f-b9cb7594a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(train_acc, val_acc, \"Accuracy\")\n",
    "plot_metrics(train_loss, val_loss, \"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e487531f-b8d7-4495-83c7-396031aa9d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_texts, test_labels):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(test_texts.to('cuda'))\n",
    "        _, test_preds = torch.max(test_outputs, 1)\n",
    "\n",
    "    test_labels = test_labels.cpu().numpy()\n",
    "    test_preds = test_preds.cpu().numpy()\n",
    "\n",
    "    precision = precision_score(test_labels, test_preds, average='weighted')\n",
    "    recall = recall_score(test_labels, test_preds, average='weighted')\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62533b8c-4081-45e0-b0fa-413357587d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c900ff-054d-4a13-905e-dfc8129f5c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, \n",
    "                            batch_first=True, bidirectional=True)\n",
    "        # Define the attention mechanism\n",
    "        self.attention = nn.Linear(hidden_size * 2, 1)  # 2 for bidirectional\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states\n",
    "        device = x.device\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Attention mechanism\n",
    "        # Compute attention weights\n",
    "        attn_weights = torch.softmax(self.attention(out), dim=1)  # Shape: [batch_size, seq_len, 1]\n",
    "        attn_output = torch.sum(attn_weights * out, dim=1)  # Weighted sum of hidden states\n",
    "\n",
    "        # Fully connected layer\n",
    "        output = self.fc(attn_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8ae01f-daa8-4b18-9ea5-7d28c011c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the LSTMAttention model\n",
    "attention_model = LSTMAttention(input_size, hidden_size, num_layers, num_classes).to('cuda')\n",
    "\n",
    "attention_optimizer = optim.AdamW(attention_model.parameters(), lr=0.005)\n",
    "attention_train_loss, attention_val_loss, attention_train_acc, attention_val_acc = train_model(\n",
    "    attention_model, train_texts, train_labels, val_texts, val_labels, epochs, attention_optimizer, criterion)\n",
    "\n",
    "plot_metrics(attention_train_acc, attention_val_acc, \"Accuracy (Attention)\")\n",
    "plot_metrics(attention_train_loss, attention_val_loss, \"Loss (Attention)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7144bf9-47e5-4689-8066-2802a2c34a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_per_class(model, test_texts, test_labels, index_to_label):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(test_texts.to('cuda'))\n",
    "        _, test_preds = torch.max(test_outputs, 1)\n",
    "\n",
    "    test_labels = test_labels.cpu().numpy()\n",
    "    test_preds = test_preds.cpu().numpy()\n",
    "\n",
    "    precision = precision_score(test_labels, test_preds, average=None)\n",
    "    recall = recall_score(test_labels, test_preds, average=None)\n",
    "\n",
    "    for i, label in index_to_label.items():\n",
    "        print(f\"Class {label}: Precision: {precision[i]:.4f}, Recall: {recall[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776f29b-b15c-4cd6-aeef-4fe7999faa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LSTM Performance:\")\n",
    "evaluate_per_class(model, test_texts, test_labels, index_to_label)\n",
    "\n",
    "print(\"\\nLSTM with Attention Performance:\")\n",
    "evaluate_per_class(attention_model, test_texts, test_labels, index_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb578fe6-3195-4162-9377-4e710ba3b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(text, model, tokenizer, index_to_label):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embedded_text = embed_sentence(text).to('cuda')\n",
    "        output = model(embedded_text.unsqueeze(0))  # Add batch dimension\n",
    "        _, prediction = torch.max(output, 1)\n",
    "    return index_to_label[prediction.item()]\n",
    "\n",
    "user_input = \"Breaking news: AI is transforming industries worldwide!\"\n",
    "predicted_category = predict_category(user_input, attention_model, tokenizer, index_to_label)\n",
    "print(f\"Predicted Category: {predicted_category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55797951-f0e3-42f5-aec2-e0ee7e80bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_errors(model, test_texts, test_labels, text_cat_pairs, index_to_label):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(test_texts.to('cuda'))\n",
    "        _, test_preds = torch.max(test_outputs, 1)\n",
    "\n",
    "    test_labels = test_labels.cpu().numpy()\n",
    "    test_preds = test_preds.cpu().numpy()\n",
    "\n",
    "    errors = (test_preds != test_labels)\n",
    "    for idx, error in enumerate(errors):\n",
    "        if error:\n",
    "            print(f\"Text: {text_cat_pairs[idx][0]}\")\n",
    "            print(f\"True Label: {index_to_label[test_labels[idx]]}\")\n",
    "            print(f\"Predicted Label: {index_to_label[test_preds[idx]]}\")\n",
    "            print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505869d9-f3b5-493c-b6ca-24f0ab55186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LSTM Errors:\")\n",
    "analyze_errors(model, test_texts, test_labels, text_cat_pairs, index_to_label)\n",
    "\n",
    "print(\"\\nLSTM with Attention Errors:\")\n",
    "analyze_errors(attention_model, test_texts, test_labels, text_cat_pairs, index_to_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
