{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1608f09d",
   "metadata": {},
   "source": [
    "```\n",
    "Courtesy: Generative AI with Python, by Fernando Amaral\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b02601",
   "metadata": {},
   "source": [
    "# Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b8437d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\mmanasanjani\\appdata\\local\\anaconda3\\lib\\site-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\mmanasanjani\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\mmanasanjani\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mmanasanjani\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mmanasanjani\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mmanasanjani\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mmanasanjani\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\mmanasanjani\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\mmanasanjani\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\mmanasanjani\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\mmanasanjani\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mmanasanjani\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mmanasanjani\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mmanasanjani\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mmanasanjani\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mmanasanjani\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mmanasanjani\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mmanasanjani\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad700664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mmanasanjani\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc0b961",
   "metadata": {},
   "source": [
    "# Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad223676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparameters():\n",
    "    max_length = int(input(\"Max length [60]: \") or \"60\")\n",
    "    do_sample = input(\"Do sample [True]: \") in [\"True\", \"true\", \"1\", \"\"]\n",
    "    temperature = float(input(\"Temperature [0.7]: \") or \"0.7\")\n",
    "    top_k = int(input(\"Top K [50]: \") or \"50\")\n",
    "    top_p = float(input(\"Top P [0.85]: \") or \"0.85\")\n",
    "    repetition_penalty = float(input(\"Repetition Penalty [1.0]: \") or \"1.0\")\n",
    "    length_penalty = float(input(\"Length Penalty [1.0]: \") or \"1.0\")\n",
    "    num_return_sequences = int(input(\"Number of return sequences [1]: \") or \"1\")\n",
    "    early_stopping = input(\"Early stopping [False]: \") in [\"True\", \"true\", \"1\"]\n",
    "    pad_token_id = int(input(\"Pad token ID [50256]: \") or \"50256\")\n",
    "\n",
    "    return (max_length, do_sample, temperature, top_k, top_p, repetition_penalty,\n",
    "            length_penalty, num_return_sequences, early_stopping, pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dff17333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_generator(model_name=\"gpt2-medium\"):\n",
    "    try:\n",
    "        generator = pipeline(\"text-generation\", model=model_name)\n",
    "        return generator\n",
    "    except Exception as e:\n",
    "        print(f\"Error on initialization: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3885ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(generator, prompt, max_length, do_sample, temperature, top_k,\n",
    "                  top_p, repetition_penalty, length_penalty, num_return_sequences,\n",
    "                  early_stopping, pad_token_id):\n",
    "    try:\n",
    "        result = generator(prompt,\n",
    "                            max_length=max_length,\n",
    "                            do_sample=do_sample,\n",
    "                            temperature=temperature,\n",
    "                            top_k=top_k,\n",
    "                            top_p=top_p,\n",
    "                            repetition_penalty=repetition_penalty,\n",
    "                            length_penalty=length_penalty,\n",
    "                            num_return_sequences=num_return_sequences,\n",
    "                            early_stopping=early_stopping,\n",
    "                            pad_token_id=pad_token_id)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error on text generation: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28f27d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    prompt = input(\"Enter your prompt: \")\n",
    "\n",
    "    adjust_hyperparams = input(\"Do you want to adjust any Hyper Parameter? [n]: \").lower() in [\"y\", \"yes\"]\n",
    "\n",
    "    if adjust_hyperparams:\n",
    "        hyperparams = get_hyperparameters()\n",
    "    else:\n",
    "        hyperparams = (60, True, 0.7, 50, 0.85, 1.0, 1.0, 1, False, 50256)\n",
    "\n",
    "    generator = initialize_generator(\"gpt2-medium\")\n",
    "    results = generate_text(generator, prompt, *hyperparams)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b32cf0",
   "metadata": {},
   "source": [
    "# Execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "267eab59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your prompt: Climate\n",
      "Do you want to adjust any Hyper Parameter? [n]: 1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result 1:\n",
      "Climate Change.\n",
      "\n",
      "\"It is not just climate change that is driving our climate change,\" he said. \"It is the way we are managing our climate change.\"\n",
      "\n",
      "\"Climate change is real, it is happening now, it is caused by human activity,\" he said. \"It is\n"
     ]
    }
   ],
   "source": [
    "results = main()\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\nResult {i + 1}:\\n{result['generated_text']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
