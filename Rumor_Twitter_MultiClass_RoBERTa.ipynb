{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5bf60e3a-28b5-43cb-9406-391a7ee9288d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bf60e3a-28b5-43cb-9406-391a7ee9288d",
        "outputId": "9303a65f-835a-4a1f-961e-17399d6fa1a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (5.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install chardet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "80990e17-0695-4df8-8a52-72300d6a15aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80990e17-0695-4df8-8a52-72300d6a15aa",
        "outputId": "77ae9d1b-6e54-4aa8-ec98-64c9303f24f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import transformers\n",
        "import random\n",
        "import chardet\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "20728c6b-ada9-4b6c-b106-8efa36c54f01",
      "metadata": {
        "id": "20728c6b-ada9-4b6c-b106-8efa36c54f01"
      },
      "outputs": [],
      "source": [
        "def random_seed(SEED):\n",
        "\n",
        "    random.seed(SEED)\n",
        "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "SEED = 508\n",
        "random_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder_path = '/content/drive/My Drive/p/'\n",
        "\n",
        "# File names to append\n",
        "file1 = 'source_tweets.txt'\n",
        "file2 = 'label.txt'\n",
        "\n",
        "# Full paths to the files\n",
        "file_path_1 = folder_path + file1\n",
        "file_path_2 = folder_path + file2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Eq7cUNa7PbJ",
        "outputId": "dbe2f16c-9c87-40c9-be16-36d77928f819"
      },
      "id": "4Eq7cUNa7PbJ",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8c121584-326c-409e-9c2e-c6fbcd1a6bbb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "id": "8c121584-326c-409e-9c2e-c6fbcd1a6bbb",
        "outputId": "a0604d7c-a1ca-4e64-9562-6f5925724c9c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                      ID                                               text\n",
              "0     731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillary...\n",
              "1     714598641827246081  an open letter to trump voters from his top st...\n",
              "2     691809004356501505  america is a nation of second chances â€”@potu...\n",
              "3     693204708933160960  brandon marshall visits and offers advice, sup...\n",
              "4     551099691702956032  rip elly may clampett: so sad to learn #beverl...\n",
              "...                  ...                                                ...\n",
              "1485  692004901455556608  .@potus just announced new reforms to address ...\n",
              "1486  760109079133990912                â€œafter school satan clubsâ€? URL\n",
              "1487  500281131057811456  breaking news: according to documents released...\n",
              "1488  523098334421319680                   ebola vaccines? URL #news #today\n",
              "1489  523545090099523584  concerned airport passenger suits up in homema...\n",
              "\n",
              "[1490 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e43709c-4605-48ae-a23f-b291d1142008\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>731166399389962242</td>\n",
              "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillary...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>714598641827246081</td>\n",
              "      <td>an open letter to trump voters from his top st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>691809004356501505</td>\n",
              "      <td>america is a nation of second chances â€”@potu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>693204708933160960</td>\n",
              "      <td>brandon marshall visits and offers advice, sup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>551099691702956032</td>\n",
              "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1485</th>\n",
              "      <td>692004901455556608</td>\n",
              "      <td>.@potus just announced new reforms to address ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1486</th>\n",
              "      <td>760109079133990912</td>\n",
              "      <td>â€œafter school satan clubsâ€? URL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1487</th>\n",
              "      <td>500281131057811456</td>\n",
              "      <td>breaking news: according to documents released...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1488</th>\n",
              "      <td>523098334421319680</td>\n",
              "      <td>ebola vaccines? URL #news #today</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1489</th>\n",
              "      <td>523545090099523584</td>\n",
              "      <td>concerned airport passenger suits up in homema...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1490 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e43709c-4605-48ae-a23f-b291d1142008')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0e43709c-4605-48ae-a23f-b291d1142008 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0e43709c-4605-48ae-a23f-b291d1142008');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b8cafdc2-fff2-4a8d-9744-92f0ac398ac3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b8cafdc2-fff2-4a8d-9744-92f0ac398ac3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b8cafdc2-fff2-4a8d-9744-92f0ac398ac3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1d5ddde9-29dd-4a4f-be78-6b55852a6656\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data0')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1d5ddde9-29dd-4a4f-be78-6b55852a6656 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data0');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data0",
              "summary": "{\n  \"name\": \"data0\",\n  \"rows\": 1490,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 111867128046871104,\n        \"min\": 80080680482123777,\n        \"max\": 780882510645370880,\n        \"num_unique_values\": 1490,\n        \"samples\": [\n          514106939173634048,\n          707786906189303808,\n          524930365400821761\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1428,\n        \"samples\": [\n          \"obama appoints fatima noor to homeland security post!! the fox in the henhouse!! #ccot #tcot #pjnet URL\",\n          \"gerrymandering is even more infuriating when you can actually see it URL URL\",\n          \"report: spider URL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           label                  ID\n",
              "0     unverified  731166399389962242\n",
              "1     unverified  714598641827246081\n",
              "2      non-rumor  691809004356501505\n",
              "3      non-rumor  693204708933160960\n",
              "4           true  551099691702956032\n",
              "...          ...                 ...\n",
              "1485   non-rumor  692004901455556608\n",
              "1486  unverified  760109079133990912\n",
              "1487  unverified  500281131057811456\n",
              "1488       false  523098334421319680\n",
              "1489  unverified  523545090099523584\n",
              "\n",
              "[1490 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a1b1255-67ee-4a97-9aa1-63fe2773234c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>unverified</td>\n",
              "      <td>731166399389962242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>unverified</td>\n",
              "      <td>714598641827246081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>non-rumor</td>\n",
              "      <td>691809004356501505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>non-rumor</td>\n",
              "      <td>693204708933160960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>true</td>\n",
              "      <td>551099691702956032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1485</th>\n",
              "      <td>non-rumor</td>\n",
              "      <td>692004901455556608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1486</th>\n",
              "      <td>unverified</td>\n",
              "      <td>760109079133990912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1487</th>\n",
              "      <td>unverified</td>\n",
              "      <td>500281131057811456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1488</th>\n",
              "      <td>false</td>\n",
              "      <td>523098334421319680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1489</th>\n",
              "      <td>unverified</td>\n",
              "      <td>523545090099523584</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1490 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a1b1255-67ee-4a97-9aa1-63fe2773234c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4a1b1255-67ee-4a97-9aa1-63fe2773234c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4a1b1255-67ee-4a97-9aa1-63fe2773234c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9fe290ba-33ba-43b9-a063-69d2c5173a81\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9fe290ba-33ba-43b9-a063-69d2c5173a81')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9fe290ba-33ba-43b9-a063-69d2c5173a81 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ce81fd2f-2610-42eb-86bf-e9e87be740a3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('label0')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ce81fd2f-2610-42eb-86bf-e9e87be740a3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('label0');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "label0",
              "summary": "{\n  \"name\": \"label0\",\n  \"rows\": 1490,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"non-rumor\",\n          \"false\",\n          \"unverified\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 111867128046871104,\n        \"min\": 80080680482123777,\n        \"max\": 780882510645370880,\n        \"num_unique_values\": 1490,\n        \"samples\": [\n          514106939173634048,\n          707786906189303808,\n          524930365400821761\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "data0=pd.read_csv(file_path_1,sep=\"\\t\", header=None, names=[\"ID\", \"text\"])\n",
        "label0=pd.read_csv(file_path_2,sep=\":\", header=None, names=[\"label\",'ID'])\n",
        "display(data0)\n",
        "display(label0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a462b86d-d13b-4493-b044-cca4722af1e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "a462b86d-d13b-4493-b044-cca4722af1e4",
        "outputId": "f6873cd2-ef06-4cf8-a0fa-ce9f1eb80967"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                      ID                                               text  \\\n",
              "0     731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillary...   \n",
              "1     714598641827246081  an open letter to trump voters from his top st...   \n",
              "2     691809004356501505  america is a nation of second chances â€”@potu...   \n",
              "3     693204708933160960  brandon marshall visits and offers advice, sup...   \n",
              "4     551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
              "...                  ...                                                ...   \n",
              "1485  692004901455556608  .@potus just announced new reforms to address ...   \n",
              "1486  760109079133990912                â€œafter school satan clubsâ€? URL   \n",
              "1487  500281131057811456  breaking news: according to documents released...   \n",
              "1488  523098334421319680                   ebola vaccines? URL #news #today   \n",
              "1489  523545090099523584  concerned airport passenger suits up in homema...   \n",
              "\n",
              "           label  \n",
              "0     unverified  \n",
              "1     unverified  \n",
              "2      non-rumor  \n",
              "3      non-rumor  \n",
              "4           true  \n",
              "...          ...  \n",
              "1485   non-rumor  \n",
              "1486  unverified  \n",
              "1487  unverified  \n",
              "1488       false  \n",
              "1489  unverified  \n",
              "\n",
              "[1490 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4971144d-99c3-4b4e-a7c0-2b930b465045\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>731166399389962242</td>\n",
              "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillary...</td>\n",
              "      <td>unverified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>714598641827246081</td>\n",
              "      <td>an open letter to trump voters from his top st...</td>\n",
              "      <td>unverified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>691809004356501505</td>\n",
              "      <td>america is a nation of second chances â€”@potu...</td>\n",
              "      <td>non-rumor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>693204708933160960</td>\n",
              "      <td>brandon marshall visits and offers advice, sup...</td>\n",
              "      <td>non-rumor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>551099691702956032</td>\n",
              "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
              "      <td>true</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1485</th>\n",
              "      <td>692004901455556608</td>\n",
              "      <td>.@potus just announced new reforms to address ...</td>\n",
              "      <td>non-rumor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1486</th>\n",
              "      <td>760109079133990912</td>\n",
              "      <td>â€œafter school satan clubsâ€? URL</td>\n",
              "      <td>unverified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1487</th>\n",
              "      <td>500281131057811456</td>\n",
              "      <td>breaking news: according to documents released...</td>\n",
              "      <td>unverified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1488</th>\n",
              "      <td>523098334421319680</td>\n",
              "      <td>ebola vaccines? URL #news #today</td>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1489</th>\n",
              "      <td>523545090099523584</td>\n",
              "      <td>concerned airport passenger suits up in homema...</td>\n",
              "      <td>unverified</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1490 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4971144d-99c3-4b4e-a7c0-2b930b465045')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4971144d-99c3-4b4e-a7c0-2b930b465045 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4971144d-99c3-4b4e-a7c0-2b930b465045');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fd45cee1-7a28-4be3-b241-2639a434f609\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd45cee1-7a28-4be3-b241-2639a434f609')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fd45cee1-7a28-4be3-b241-2639a434f609 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e1910ff6-2f1a-4cce-a959-0bf74a36b68e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e1910ff6-2f1a-4cce-a959-0bf74a36b68e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1490,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 111867128046871104,\n        \"min\": 80080680482123777,\n        \"max\": 780882510645370880,\n        \"num_unique_values\": 1490,\n        \"samples\": [\n          514106939173634048,\n          707786906189303808,\n          524930365400821761\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1428,\n        \"samples\": [\n          \"obama appoints fatima noor to homeland security post!! the fox in the henhouse!! #ccot #tcot #pjnet URL\",\n          \"gerrymandering is even more infuriating when you can actually see it URL URL\",\n          \"report: spider URL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"non-rumor\",\n          \"false\",\n          \"unverified\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "data = pd.merge(data0, label0, on=\"ID\", how=\"left\")\n",
        "display(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c02edb46-4685-411a-8c1a-3200b8546580",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "c02edb46-4685-411a-8c1a-3200b8546580",
        "outputId": "d236234a-965d-4b44-81a0-e4a2a555a1d9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                      ID                                               text  \\\n",
              "0     731166399389962242  ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillary...   \n",
              "1     714598641827246081  an open letter to trump voters from his top st...   \n",
              "2     691809004356501505  america is a nation of second chances â€”@potu...   \n",
              "3     693204708933160960  brandon marshall visits and offers advice, sup...   \n",
              "4     551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
              "...                  ...                                                ...   \n",
              "1485  692004901455556608  .@potus just announced new reforms to address ...   \n",
              "1486  760109079133990912                â€œafter school satan clubsâ€? URL   \n",
              "1487  500281131057811456  breaking news: according to documents released...   \n",
              "1488  523098334421319680                   ebola vaccines? URL #news #today   \n",
              "1489  523545090099523584  concerned airport passenger suits up in homema...   \n",
              "\n",
              "         targets  \n",
              "0     unverified  \n",
              "1     unverified  \n",
              "2      non-rumor  \n",
              "3      non-rumor  \n",
              "4           true  \n",
              "...          ...  \n",
              "1485   non-rumor  \n",
              "1486  unverified  \n",
              "1487  unverified  \n",
              "1488       false  \n",
              "1489  unverified  \n",
              "\n",
              "[1490 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acabce68-50ee-4313-9d1d-e487bc608fee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "      <th>targets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>731166399389962242</td>\n",
              "      <td>ðŸ”¥ca kkk grand wizard ðŸ”¥ endorses @hillary...</td>\n",
              "      <td>unverified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>714598641827246081</td>\n",
              "      <td>an open letter to trump voters from his top st...</td>\n",
              "      <td>unverified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>691809004356501505</td>\n",
              "      <td>america is a nation of second chances â€”@potu...</td>\n",
              "      <td>non-rumor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>693204708933160960</td>\n",
              "      <td>brandon marshall visits and offers advice, sup...</td>\n",
              "      <td>non-rumor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>551099691702956032</td>\n",
              "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
              "      <td>true</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1485</th>\n",
              "      <td>692004901455556608</td>\n",
              "      <td>.@potus just announced new reforms to address ...</td>\n",
              "      <td>non-rumor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1486</th>\n",
              "      <td>760109079133990912</td>\n",
              "      <td>â€œafter school satan clubsâ€? URL</td>\n",
              "      <td>unverified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1487</th>\n",
              "      <td>500281131057811456</td>\n",
              "      <td>breaking news: according to documents released...</td>\n",
              "      <td>unverified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1488</th>\n",
              "      <td>523098334421319680</td>\n",
              "      <td>ebola vaccines? URL #news #today</td>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1489</th>\n",
              "      <td>523545090099523584</td>\n",
              "      <td>concerned airport passenger suits up in homema...</td>\n",
              "      <td>unverified</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1490 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acabce68-50ee-4313-9d1d-e487bc608fee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-acabce68-50ee-4313-9d1d-e487bc608fee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-acabce68-50ee-4313-9d1d-e487bc608fee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-88444bf1-1dd3-4e57-abd6-a00a4f7fe4cb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88444bf1-1dd3-4e57-abd6-a00a4f7fe4cb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-88444bf1-1dd3-4e57-abd6-a00a4f7fe4cb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c8110241-6274-4372-9056-51b72f912fdc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c8110241-6274-4372-9056-51b72f912fdc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1490,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 111867128046871104,\n        \"min\": 80080680482123777,\n        \"max\": 780882510645370880,\n        \"num_unique_values\": 1490,\n        \"samples\": [\n          514106939173634048,\n          707786906189303808,\n          524930365400821761\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1428,\n        \"samples\": [\n          \"obama appoints fatima noor to homeland security post!! the fox in the henhouse!! #ccot #tcot #pjnet URL\",\n          \"gerrymandering is even more infuriating when you can actually see it URL URL\",\n          \"report: spider URL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"targets\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"non-rumor\",\n          \"false\",\n          \"unverified\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['false', 'non-rumor', 'true', 'unverified']\n"
          ]
        }
      ],
      "source": [
        "data.columns=['ID','text','targets']\n",
        "display(data)\n",
        "classes=sorted(data['targets'].unique().tolist())\n",
        "print(classes)\n",
        "class_names=['false', 'non-rumor', 'true', 'unverified']\n",
        "N=list(range(len(class_names)))\n",
        "normal_mapping=dict(zip(class_names,N))\n",
        "reverse_mapping=dict(zip(N,class_names))\n",
        "data['targets']=data['targets'].map(normal_mapping)\n",
        "data=data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6543ca81-041f-4806-bb54-20c4967b2a85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6543ca81-041f-4806-bb54-20c4967b2a85",
        "outputId": "feb58948-9c8a-416e-8557-8ebcd6a4de58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1490\n"
          ]
        }
      ],
      "source": [
        "print(len(data))\n",
        "data=data.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "dcf0c025-79d6-4e4a-bba0-f03a07014f30",
      "metadata": {
        "id": "dcf0c025-79d6-4e4a-bba0-f03a07014f30"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "88cef5ab-4a07-4009-b356-e8b0ae59d90c",
      "metadata": {
        "id": "88cef5ab-4a07-4009-b356-e8b0ae59d90c"
      },
      "outputs": [],
      "source": [
        "tokenizer = transformers.RobertaTokenizer.from_pretrained(\"roberta-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "af3cc6d5-6f51-4b8d-93ff-c09c8b4cc490",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "af3cc6d5-6f51-4b8d-93ff-c09c8b4cc490",
        "outputId": "7e87e7ca-68a8-4ee7-d6fc-f7f38e353631"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>meet the south american goliath birdeater -- a spider the size of a puppy: URL URL</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "test_s = train['text'].iloc[0]\n",
        "result1 = tokenizer.encode_plus(test_s)\n",
        "tokenizer.decode(result1[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ee551cbd-0308-449b-b93c-cd822ba2ac02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee551cbd-0308-449b-b93c-cd822ba2ac02",
        "outputId": "2d2fad37-aeb5-4065-cd68-ca889e5dfe99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "len(test_s.split(\" \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c6a8a3bf-7bbd-48cf-a3a6-3334b4271e2d",
      "metadata": {
        "id": "c6a8a3bf-7bbd-48cf-a3a6-3334b4271e2d"
      },
      "outputs": [],
      "source": [
        "result2 = tokenizer.encode_plus(\n",
        "    test_s,\n",
        "    add_special_tokens = True,\n",
        "    max_length = 8,\n",
        "    pad_to_max_length = True,\n",
        "    truncation = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b090e847-4f91-4b6c-8f6b-d1c74c7e676d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "b090e847-4f91-4b6c-8f6b-d1c74c7e676d",
        "outputId": "b0412885-7e28-4560-a91d-740ebce27fcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s>meet the south american g</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "tokenizer.decode(result2[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "927dcc8b-8248-4b6f-9463-1ef024034f3b",
      "metadata": {
        "id": "927dcc8b-8248-4b6f-9463-1ef024034f3b"
      },
      "outputs": [],
      "source": [
        "max_sens = 8\n",
        "train = train.sort_values('targets').reset_index(drop=True)\n",
        "train[\"kfold\"] = train.index % 5\n",
        "p_train = train[train[\"kfold\"]!=0].reset_index(drop=True)\n",
        "p_valid = train[train[\"kfold\"]==0].reset_index(drop=True)\n",
        "p_test=test.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "44e2e59f-6909-4160-9a0a-b7b498e4d819",
      "metadata": {
        "id": "44e2e59f-6909-4160-9a0a-b7b498e4d819"
      },
      "outputs": [],
      "source": [
        "class BERTDataSet(Dataset):\n",
        "\n",
        "    def __init__(self,sentences,targets):\n",
        "        self.sentences = sentences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        bert_sens = tokenizer.encode_plus(\n",
        "                                sentence,\n",
        "                                add_special_tokens = True,\n",
        "                                max_length = max_sens,\n",
        "                                pad_to_max_length = True,\n",
        "                                return_attention_mask = True)\n",
        "\n",
        "        ids = torch.tensor(bert_sens['input_ids'], dtype=torch.long)\n",
        "        mask = torch.tensor(bert_sens['attention_mask'], dtype=torch.long)\n",
        "\n",
        "        target = torch.tensor(self.targets[idx],dtype=torch.float)\n",
        "\n",
        "        return {\n",
        "                'ids': ids,\n",
        "                'mask': mask,\n",
        "                'targets': target\n",
        "            }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "63589e78-1ea3-466e-8a38-f0990047a445",
      "metadata": {
        "id": "63589e78-1ea3-466e-8a38-f0990047a445"
      },
      "outputs": [],
      "source": [
        "train_dataset = BERTDataSet(p_train[\"text\"],p_train['targets'])\n",
        "valid_dataset = BERTDataSet(p_valid[\"text\"],p_valid['targets'])\n",
        "test_dataset = BERTDataSet(p_test[\"text\"],p_test['targets'])\n",
        "\n",
        "train_batch = 16\n",
        "valid_batch = 32\n",
        "test_batch = 32\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=8,pin_memory=True)\n",
        "valid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch,shuffle = False,num_workers=8,pin_memory=True)\n",
        "test_dataloader = DataLoader(test_dataset,batch_size=test_batch,shuffle = False,num_workers=8,pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "5ae65a8a-9823-419d-8341-c2d57f931849",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "f3e1817f135a43c78e6bd5fd270f73e2",
            "314cd2e02eea461dad1f2f4eca7f42ab",
            "928eb20973e945649e8867ed42216095",
            "36021f9d80a64cbf9e05dcbad95caf3d",
            "8a8e6f2a10354621a98078b547411d8b",
            "c77b84a91c0d4b2e9eceff90acd855be",
            "0aff0c1a29a44a2cb1766932f938a6a9",
            "b95a6448a1a84769bbda747023604e55",
            "a7d3694c93a0497a8e85aa04e67ccd46",
            "b4f0b3dde690474c934e7054a730d02c",
            "c72792359a434c5bbd06425ea9c6168d"
          ]
        },
        "id": "5ae65a8a-9823-419d-8341-c2d57f931849",
        "outputId": "427d328e-7598-49ff-ac11-70d41b5ddf99"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3e1817f135a43c78e6bd5fd270f73e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = transformers.RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "0caa14d5-e78d-4ed3-8c76-7b0b698ffc61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0caa14d5-e78d-4ed3-8c76-7b0b698ffc61",
        "outputId": "bf6b7631-56fc-48c8-cc2c-9fd122daea31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "model.to(device)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "d09f65cf-ca75-447c-bd74-0fdbac7a4233",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d09f65cf-ca75-447c-bd74-0fdbac7a4233",
        "outputId": "ddf71c19-8e57-49a4-c9c4-e94886eac6cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ],
      "source": [
        "for a in train_dataloader:\n",
        "    ids = a[\"ids\"].to(device)\n",
        "    mask = a[\"mask\"].to(device)\n",
        "    output = model(ids,mask)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "b58c8c6e-31b2-4da0-9f15-f1e9e329f87d",
      "metadata": {
        "id": "b58c8c6e-31b2-4da0-9f15-f1e9e329f87d"
      },
      "outputs": [],
      "source": [
        "output = output[\"logits\"].squeeze(-1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "a860dcbe-7990-458e-ad7a-53fe29e578c4",
      "metadata": {
        "id": "a860dcbe-7990-458e-ad7a-53fe29e578c4"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW\n",
        "LR=2e-5\n",
        "optimizer = AdamW(model.parameters(), LR,betas=(0.9,0.999), weight_decay=1e-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "55875c2d-fe05-4eb1-93e5-65737f921b22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55875c2d-fe05-4eb1-93e5-65737f921b22",
        "outputId": "7f992e77-377c-4f9f-fedb-44e76338ea10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "595\n"
          ]
        }
      ],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 10\n",
        "train_steps = int(len(p_train)/train_batch*epochs)\n",
        "print(train_steps)\n",
        "num_steps = int(train_steps*0.1)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "f52f4a2e-499b-4a75-927e-7bc7984363d7",
      "metadata": {
        "id": "f52f4a2e-499b-4a75-927e-7bc7984363d7"
      },
      "outputs": [],
      "source": [
        "def loss_fn(output,target):\n",
        "    return torch.sqrt(nn.MSELoss()(output,target))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "5eaa5ce4-e274-4166-8ed4-4d5d3f83cfc5",
      "metadata": {
        "id": "5eaa5ce4-e274-4166-8ed4-4d5d3f83cfc5"
      },
      "outputs": [],
      "source": [
        "def training(\n",
        "    train_dataloader,\n",
        "    model,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    device=None,  # Default device set to None\n",
        "    scaler=None,  # Default scaler set to None\n",
        "    loss_fn=None,  # Default loss_fn set to None\n",
        "    verbose=False\n",
        "):\n",
        "    # Set default values if not passed\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    if scaler is None:\n",
        "        scaler = torch.cuda.amp.GradScaler()  # For mixed precision training\n",
        "    if loss_fn is None:\n",
        "        loss_fn = torch.nn.CrossEntropyLoss()  # Example loss function\n",
        "\n",
        "    model.train()\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    allpreds = []\n",
        "    alltargets = []\n",
        "\n",
        "    for a in train_dataloader:\n",
        "        losses = []\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "\n",
        "            ids = a[\"ids\"].to(device, non_blocking=True)\n",
        "            mask = a[\"mask\"].to(device, non_blocking=True)\n",
        "\n",
        "            output = model(ids, mask)\n",
        "            output = output[\"logits\"].squeeze(-1)\n",
        "\n",
        "            target = a[\"targets\"].to(device, non_blocking=True)\n",
        "            target = target.long()\n",
        "\n",
        "            output = output.view(-1, 4)\n",
        "            target = target.view(-1)\n",
        "\n",
        "            #print('output.shape', output.shape)\n",
        "            #print('target.shape', target.shape)\n",
        "\n",
        "            loss = loss_fn(output, target)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            predicted_class = torch.argmax(output, dim=-1)\n",
        "\n",
        "            allpreds.append(predicted_class.detach().cpu().numpy())\n",
        "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        del loss\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    allpreds = np.concatenate(allpreds)\n",
        "    alltargets = np.concatenate(alltargets)\n",
        "    losses = np.mean(losses)\n",
        "    train_rme_loss = np.sqrt(mean_squared_error(alltargets, allpreds))\n",
        "\n",
        "    return losses, train_rme_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "5d072e33-4253-4350-8c5a-5a7b65bbee62",
      "metadata": {
        "id": "5d072e33-4253-4350-8c5a-5a7b65bbee62"
      },
      "outputs": [],
      "source": [
        "def validating(valid_dataloader, model, device=None, loss_fn=None):\n",
        "    # Set default values if not passed\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    if loss_fn is None:\n",
        "        loss_fn = torch.nn.CrossEntropyLoss()  # Example loss function\n",
        "\n",
        "    model.eval()\n",
        "    allpreds = []\n",
        "    alltargets = []\n",
        "    losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for a in valid_dataloader:\n",
        "            ids = a[\"ids\"].to(device)\n",
        "            mask = a[\"mask\"].to(device)\n",
        "\n",
        "            output = model(ids, mask)\n",
        "            output = output[\"logits\"].squeeze(-1)  # Adjust according to model output\n",
        "\n",
        "            target = a[\"targets\"].to(device, non_blocking=True)\n",
        "            target = target.long()\n",
        "\n",
        "            output = output.view(-1, 4)  # Adjust if necessary\n",
        "            target = target.view(-1)\n",
        "\n",
        "            #print('output.shape', output.shape)\n",
        "            #print('target.shape', target.shape)\n",
        "\n",
        "            loss = loss_fn(output, target)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            predicted_class = torch.argmax(output, dim=-1)  # Predicted class from logits\n",
        "\n",
        "            allpreds.append(predicted_class.detach().cpu().numpy())\n",
        "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n",
        "\n",
        "            del loss  # To avoid unnecessary memory usage\n",
        "\n",
        "    allpreds = np.concatenate(allpreds)\n",
        "    alltargets = np.concatenate(alltargets)\n",
        "    losses = np.mean(losses)\n",
        "    valid_rmse_loss = np.sqrt(mean_squared_error(alltargets, allpreds))\n",
        "\n",
        "    return allpreds, losses, valid_rmse_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "59af2274-57c6-419c-9de6-8aa44d0882fa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59af2274-57c6-419c-9de6-8aa44d0882fa",
        "outputId": "0d4792c3-dd9f-41a7-b225-91643509e89b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------0start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 1.6850680563910363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.8635459069420144\n",
            "Save first model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:13<02:04, 13.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------1start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 1.730535584807003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.2642493266095245\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:33<02:18, 17.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------2start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 1.3446095404872598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.2542813708742453\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:48<01:52, 16.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------3start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.9857324259300317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.1222362611952184\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [01:05<01:38, 16.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------4start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.7760853686775322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 50%|█████     | 5/10 [01:12<01:05, 13.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.230708881687475\n",
            "---------------5start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.5506840161329764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.0785081901951379\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [01:25<00:52, 13.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------6start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.3860092588965063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 70%|███████   | 7/10 [01:31<00:32, 10.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.1388903062661975\n",
            "---------------7start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.3090112179899811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 80%|████████  | 8/10 [01:38<00:18,  9.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.0958270028082362\n",
            "---------------8start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.2748652250108257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 90%|█████████ | 9/10 [01:45<00:08,  8.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.1407257471125665\n",
            "---------------9start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.209931783253863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 10/10 [01:53<00:00, 11.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.1147546027120867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "trainlosses = []\n",
        "vallosses = []\n",
        "bestscore = None\n",
        "trainscores = []\n",
        "validscores = []\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "\n",
        "    print(\"---------------\" + str(epoch) + \"start-------------\")\n",
        "\n",
        "    trainloss,trainscore = training(train_dataloader,model,optimizer,scheduler)\n",
        "    trainlosses.append(trainloss)\n",
        "    trainscores.append(trainscore)\n",
        "\n",
        "    print(\"trainscore is \" + str(trainscore))\n",
        "\n",
        "    preds,validloss,valscore=validating(valid_dataloader,model)\n",
        "    vallosses.append(validloss)\n",
        "    validscores.append(valscore)\n",
        "\n",
        "    print(\"valscore is \" + str(valscore))\n",
        "\n",
        "    if bestscore is None:\n",
        "        bestscore = valscore\n",
        "\n",
        "        print(\"Save first model\")\n",
        "\n",
        "        state = {\n",
        "                        'state_dict': model.state_dict(),\n",
        "                        'optimizer_dict': optimizer.state_dict(),\n",
        "                        \"bestscore\":bestscore\n",
        "                    }\n",
        "\n",
        "        torch.save(state, \"model0.pth\")\n",
        "\n",
        "    elif bestscore > valscore:\n",
        "\n",
        "        bestscore = valscore\n",
        "        print(\"found better point\")\n",
        "        state = {\n",
        "                        'state_dict': model.state_dict(),\n",
        "                        'optimizer_dict': optimizer.state_dict(),\n",
        "                        \"bestscore\":bestscore\n",
        "                    }\n",
        "\n",
        "        torch.save(state, \"model0.pth\")\n",
        "\n",
        "    else:\n",
        "        pass\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "75c3ef18-094f-4da5-a0aa-e23bbe34540c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "75c3ef18-094f-4da5-a0aa-e23bbe34540c",
        "outputId": "e8185f58-445c-4cc1-b80a-1226dcb9e0cb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.scatter(p_valid['targets'],preds, alpha=0.2)\n",
        "plt.title('Validation Prediction Result')\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Prediction')\n",
        "plt.show()\n",
        "\n",
        "x = np.arange(epochs)\n",
        "plt.title('Validation Losses')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(x,trainlosses)\n",
        "plt.plot(x,vallosses)\n",
        "plt.show()\n",
        "\n",
        "x = np.arange(epochs)\n",
        "plt.title('Validation Scores')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Score')\n",
        "plt.plot(x,trainscores)\n",
        "plt.plot(x,validscores)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "8c750663-d081-482a-823a-2dd65f075643",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c750663-d081-482a-823a-2dd65f075643",
        "outputId": "7f8b83d4-a80f-4dcc-91e6-af0e9e81558b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 1, 0, 1, 2, 2, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 1, 2, 2, 3, 0, 1, 0, 0, 0, 0, 0, 1, 3, 0, 2, 0, 0, 1, 0, 0, 2, 3, 3, 0, 1, 0, 0, 1, 1, 0, 1, 3, 1, 1, 3, 1, 2, 1, 1, 0, 3, 3, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 2, 2, 0, 3, 1, 1, 2, 1, 1, 1, 3, 3, 1, 1, 0, 2, 1, 3, 1, 0, 1, 1, 2, 1, 1, 3, 2, 1, 1, 3, 3, 1, 1, 0, 1, 1, 2, 0, 1, 1, 1, 2, 0, 2, 2, 3, 2, 2, 2, 2, 2, 0, 1, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 3, 1, 3, 2, 2, 2, 1, 3, 3, 1, 1, 0, 3, 1, 2, 3, 0, 3, 2, 0, 3, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 2, 3, 3, 3, 3, 1, 2, 3, 0, 3, 3, 3, 2, 0, 3, 3, 3, 1, 1, 3, 3, 1, 2, 2, 3, 3, 3, 1, 2, 3, 3, 2, 0, 3, 3]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       false     0.7021    0.5500    0.6168        60\n",
            "   non-rumor     0.5469    0.5738    0.5600        61\n",
            "        true     0.6250    0.7759    0.6923        58\n",
            "  unverified     0.5714    0.5333    0.5517        60\n",
            "\n",
            "    accuracy                         0.6067       239\n",
            "   macro avg     0.6114    0.6082    0.6052       239\n",
            "weighted avg     0.6110    0.6067    0.6043       239\n",
            "\n"
          ]
        }
      ],
      "source": [
        "val_true = p_valid['targets']\n",
        "val_pred = []\n",
        "for p in preds:\n",
        "    val_pred+=[p]\n",
        "print(val_pred)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(val_true,val_pred,target_names=class_names,digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "e877b235-a5ad-4f02-bf91-c5bdc8271a45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e877b235-a5ad-4f02-bf91-c5bdc8271a45",
        "outputId": "864a809a-66d2-478f-eef5-c8512e31ed5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------0start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 1.6564922039737504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.8307005312574864\n",
            "Save first model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:15<02:20, 15.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------1start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 1.5242014061625007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.1498590053643851\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:31<02:05, 15.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------2start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 1.2749092101905732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 30%|███       | 3/10 [00:38<01:21, 11.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.183922987430924\n",
            "---------------3start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 1.01147664073542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 40%|████      | 4/10 [00:43<00:54,  9.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.1553043034078958\n",
            "---------------4start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.7052493921597224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 50%|█████     | 5/10 [00:49<00:39,  7.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.1821546175306148\n",
            "---------------5start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.496578006645638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.0668061275637348\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [01:01<00:37,  9.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------6start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.3503857864845679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 70%|███████   | 7/10 [01:07<00:25,  8.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.068765369118003\n",
            "---------------7start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.18324348334055046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.060906693612733\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [01:22<00:20, 10.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------8start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.27676742919568526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 90%|█████████ | 9/10 [01:27<00:08,  8.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.0648432811400563\n",
            "---------------9start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.15535222140911636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.0510007185821764\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [01:41<00:00, 10.16s/it]\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------0start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 1.7067506858249513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.8663315025233123\n",
            "Save first model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:11<01:40, 11.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------1start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 1.5986105077709065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.620509308880411\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:25<01:45, 13.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------2start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 1.355940420328299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.2161379842101205\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:41<01:39, 14.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------3start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 1.0041841186927827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.152272143391905\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:59<01:34, 15.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------4start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.7290038003196575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 50%|█████     | 5/10 [01:06<01:02, 12.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.152272143391905\n",
            "---------------5start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.5465730860230678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 60%|██████    | 6/10 [01:11<00:40, 10.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.1703622939755296\n",
            "---------------6start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.3761773969316394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.1227217828476797\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [01:24<00:33, 11.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------7start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.33490196944846595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 80%|████████  | 8/10 [01:30<00:18,  9.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.159542071304897\n",
            "---------------8start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.214759384641055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.0923723316362282\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [01:44<00:10, 10.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------9start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.20730880155785547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.0904474449748143\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:02<00:00, 12.21s/it]\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------0start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 1.4333552726125527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.8663315025233123\n",
            "Save first model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:12<01:54, 12.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------1start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 1.5721635135085497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.5489220974166344\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:25<01:43, 12.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------2start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 1.2518330375407125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.2702146976599116\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:41<01:40, 14.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------3start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.9433647793500873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 40%|████      | 4/10 [00:48<01:08, 11.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.3363062095621219\n",
            "---------------4start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.6635145607498332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.2213093951392753\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [01:04<01:05, 13.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------5start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.4931395165764191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.1577288691458727\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [01:19<00:55, 13.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------6start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.3761773969316394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.1170940692993878\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [01:31<00:39, 13.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------7start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.20982172726556322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.0962119650272513\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [01:42<00:24, 12.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------8start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.24443491500388395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 90%|█████████ | 9/10 [01:48<00:10, 10.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.1133264563097958\n",
            "---------------9start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.15185781720314007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 10/10 [01:54<00:00, 11.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.1189731186834357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------0start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 1.7067506858249513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.8708286933869707\n",
            "Save first model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:13<01:57, 13.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------1start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 1.6829394271048448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.198738833072478\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:27<01:52, 14.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------2start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 1.329002400093742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 30%|███       | 3/10 [00:33<01:11, 10.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.318899464826386\n",
            "---------------3start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 1.1116874815359636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.1540939186692059\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:46<01:08, 11.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------4start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.8267031844236893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 50%|█████     | 5/10 [00:52<00:47,  9.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.1793033123505625\n",
            "---------------5start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.5746204653902287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 60%|██████    | 6/10 [00:59<00:34,  8.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.2144092868412966\n",
            "---------------6start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.4658123356840947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 70%|███████   | 7/10 [01:05<00:22,  7.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.2022388079165072\n",
            "---------------7start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.29673273237950815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 80%|████████  | 8/10 [01:11<00:14,  7.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.1952286093343936\n",
            "---------------8start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.24010829143171164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 90%|█████████ | 9/10 [01:17<00:06,  6.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.1846355323633573\n",
            "---------------9start-------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.19693670832517202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 10/10 [01:23<00:00,  8.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 1.1793033123505625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "bestscores = []\n",
        "bestscores.append(bestscore)\n",
        "\n",
        "for fold in range(1,5):\n",
        "\n",
        "    # initializing the data\n",
        "    p_train = train[train[\"kfold\"]!=fold].reset_index(drop=True)\n",
        "    p_valid = train[train[\"kfold\"]==fold].reset_index(drop=True)\n",
        "\n",
        "    train_dataset = BERTDataSet(p_train[\"text\"],p_train['targets'])\n",
        "    valid_dataset = BERTDataSet(p_valid[\"text\"],p_valid['targets'])\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=4,pin_memory=True)\n",
        "    valid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch,shuffle = False,num_workers=4,pin_memory=True)\n",
        "\n",
        "    model = transformers.RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=4)\n",
        "\n",
        "    model.to(device)\n",
        "    LR=2e-5\n",
        "    optimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2) # AdamW optimizer\n",
        "    train_steps = int(len(p_train)/train_batch*epochs)\n",
        "    num_steps = int(train_steps*0.1)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)\n",
        "\n",
        "    trainlosses = []\n",
        "    vallosses = []\n",
        "    bestscore = None\n",
        "    trainscores = []\n",
        "    validscores = []\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        print(\"---------------\" + str(epoch) + \"start-------------\")\n",
        "\n",
        "        trainloss,trainscore = training(train_dataloader,model,optimizer,scheduler)\n",
        "        trainlosses.append(trainloss)\n",
        "        trainscores.append(trainscore)\n",
        "\n",
        "        print(\"trainscore is \" + str(trainscore))\n",
        "\n",
        "        preds,validloss,valscore=validating(valid_dataloader,model)\n",
        "        vallosses.append(validloss)\n",
        "        validscores.append(valscore)\n",
        "\n",
        "        print(\"valscore is \" + str(valscore))\n",
        "\n",
        "        if bestscore is None:\n",
        "            bestscore = valscore\n",
        "\n",
        "            print(\"Save first model\")\n",
        "\n",
        "            state = {\n",
        "                            'state_dict': model.state_dict(),\n",
        "                            'optimizer_dict': optimizer.state_dict(),\n",
        "                            \"bestscore\":bestscore\n",
        "                        }\n",
        "\n",
        "            torch.save(state, \"model\" + str(fold) + \".pth\")\n",
        "\n",
        "        elif bestscore > valscore:\n",
        "            bestscore = valscore\n",
        "            print(\"found better point\")\n",
        "\n",
        "            state = {\n",
        "                            'state_dict': model.state_dict(),\n",
        "                            'optimizer_dict': optimizer.state_dict(),\n",
        "                            \"bestscore\":bestscore\n",
        "                        }\n",
        "            torch.save(state, \"model\"+ str(fold) + \".pth\")\n",
        "\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "\n",
        "    bestscores.append(bestscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "d97d5fc7-7458-41a5-b9c3-1fb8edfe176d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d97d5fc7-7458-41a5-b9c3-1fb8edfe176d",
        "outputId": "a843afb4-87ea-4544-f58d-decad92963d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0785081901951379,\n",
              " 1.0510007185821764,\n",
              " 1.0904474449748143,\n",
              " 1.0962119650272513,\n",
              " 1.1540939186692059]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "bestscores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "cdc0e3a3-d5e6-45b9-b8be-2c82eb12bdf3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdc0e3a3-d5e6-45b9-b8be-2c82eb12bdf3",
        "outputId": "56df76aa-57f6-455f-c7a4-6307c8a79989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv = 1.0940524474897173\n"
          ]
        }
      ],
      "source": [
        "np.mean(bestscores)\n",
        "print(\"cv = \" + str(np.mean(bestscores)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "d22787ac-4ca4-4bd5-bfd4-d0daf2983fa5",
      "metadata": {
        "id": "d22787ac-4ca4-4bd5-bfd4-d0daf2983fa5"
      },
      "outputs": [],
      "source": [
        "def predicting(test_dataloader,model):\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    allpreds = []\n",
        "    preds = []\n",
        "    allvalloss=0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for a in test_dataloader:\n",
        "\n",
        "            ids = a[\"ids\"].to(device)\n",
        "            mask = a[\"mask\"].to(device)\n",
        "\n",
        "            output = model(ids,mask)\n",
        "            output = output[\"logits\"].squeeze(-1)\n",
        "            preds.append(output.cpu().numpy())\n",
        "\n",
        "        preds = np.concatenate(preds)\n",
        "        allpreds.append(preds)\n",
        "\n",
        "    return allpreds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "370e1add-61c1-43cd-8371-6bd533faf8ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "370e1add-61c1-43cd-8371-6bd533faf8ba",
        "outputId": "5903d512-0a22-4a92-f8d9-e9b65cf6b8c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ],
      "source": [
        "tpreds = predicting(test_dataloader,model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "d3d3d21d-e4d0-483d-9309-bd6a6de3095a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3d3d21d-e4d0-483d-9309-bd6a6de3095a",
        "outputId": "9ad593e5-e8fc-4384-a489-64b7f062b5d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 2, 1, 2, 2, 3, 3, 0, 0, 3, 1, 3, 1, 1, 3, 2, 0, 0, 2, 2, 3, 1, 0, 3, 2, 3, 0, 0, 2, 0, 3, 1, 1, 3, 3, 2, 2, 0, 1, 3, 2, 3, 0, 3, 1, 3, 3, 3, 0, 0, 1, 3, 0, 3, 3, 3, 0, 1, 0, 1, 3, 2, 3, 3, 2, 3, 1, 0, 1, 3, 0, 3, 3, 0, 0, 1, 3, 3, 1, 1, 0, 1, 2, 3, 1, 2, 2, 1, 2, 2, 3, 1, 0, 3, 2, 2, 1, 0, 0, 2, 3, 2, 1, 0, 2, 2, 3, 1, 1, 0, 3, 0, 2, 3, 0, 2, 3, 2, 1, 3, 2, 1, 1, 2, 3, 3, 2, 2, 1, 2, 0, 2, 2, 2, 1, 3, 3, 3, 2, 1, 0, 2, 2, 1, 3, 3, 2, 3, 2, 3, 0, 3, 1, 3, 1, 1, 2, 2, 0, 0, 0, 3, 2, 2, 2, 3, 1, 0, 2, 3, 2, 1, 2, 3, 2, 0, 1, 2, 2, 3, 2, 0, 2, 2, 2, 2, 2, 0, 0, 1, 1, 0, 1, 2, 0, 0, 1, 0, 1, 2, 1, 1, 1, 0, 0, 0, 2, 2, 1, 0, 2, 2, 1, 0, 2, 0, 1, 2, 1, 0, 0, 0, 1, 2, 3, 2, 2, 2, 0, 3, 3, 0, 1, 0, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 0, 2, 2, 0, 3, 0, 3, 2, 1, 3, 3, 3, 0, 2, 2, 0, 3, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 3, 2, 0, 1, 2, 2, 3, 0, 0, 2, 3, 2, 0, 1, 1, 0, 2, 0, 0, 0, 2, 1, 3, 2, 3, 3, 3]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       false     0.6111    0.6197    0.6154        71\n",
            "   non-rumor     0.5231    0.4928    0.5075        69\n",
            "        true     0.6667    0.7143    0.6897        84\n",
            "  unverified     0.5493    0.5270    0.5379        74\n",
            "\n",
            "    accuracy                         0.5940       298\n",
            "   macro avg     0.5875    0.5884    0.5876       298\n",
            "weighted avg     0.5910    0.5940    0.5921       298\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_true = p_test['targets']\n",
        "test_pred = []\n",
        "for p in tpreds[0]:\n",
        "    test_pred+=[np.argmax(p)]\n",
        "print(test_pred)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_true,test_pred,target_names=class_names,digits=4))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f3e1817f135a43c78e6bd5fd270f73e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_314cd2e02eea461dad1f2f4eca7f42ab",
              "IPY_MODEL_928eb20973e945649e8867ed42216095",
              "IPY_MODEL_36021f9d80a64cbf9e05dcbad95caf3d"
            ],
            "layout": "IPY_MODEL_8a8e6f2a10354621a98078b547411d8b"
          }
        },
        "314cd2e02eea461dad1f2f4eca7f42ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c77b84a91c0d4b2e9eceff90acd855be",
            "placeholder": "​",
            "style": "IPY_MODEL_0aff0c1a29a44a2cb1766932f938a6a9",
            "value": "model.safetensors: 100%"
          }
        },
        "928eb20973e945649e8867ed42216095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b95a6448a1a84769bbda747023604e55",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7d3694c93a0497a8e85aa04e67ccd46",
            "value": 498818054
          }
        },
        "36021f9d80a64cbf9e05dcbad95caf3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4f0b3dde690474c934e7054a730d02c",
            "placeholder": "​",
            "style": "IPY_MODEL_c72792359a434c5bbd06425ea9c6168d",
            "value": " 499M/499M [00:03&lt;00:00, 169MB/s]"
          }
        },
        "8a8e6f2a10354621a98078b547411d8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c77b84a91c0d4b2e9eceff90acd855be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aff0c1a29a44a2cb1766932f938a6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b95a6448a1a84769bbda747023604e55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7d3694c93a0497a8e85aa04e67ccd46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4f0b3dde690474c934e7054a730d02c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c72792359a434c5bbd06425ea9c6168d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}